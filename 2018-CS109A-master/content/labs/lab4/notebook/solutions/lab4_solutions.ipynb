{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS-109A Introduction to Data Science\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 4: Multiple and Polynomial Regression \n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2018**<br/>\n",
    "**Instructors:** Pavlos Protopapas and Kevin Rader<br/>\n",
    "**Lab Instructor:** Rahul Dave<br/>\n",
    "**Authors:** Rahul Dave, David Sondak, Will Claybaugh, Pavlos Protopapas\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RUN THIS CELL TO GET THE RIGHT FORMATTING \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "<ol start=\"0\">\n",
    "<li> Learning Goals </li>\n",
    "<li> Polynomial Regression, and Revisiting the Cab Data</li>\n",
    "<li> Multiple regression and exploring the Football data </li>\n",
    "<li> A nice trick for forward-backwards </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "After this lab, you should be able to\n",
    " - Implement arbitrary multiple regression models in both SK-learn and Statsmodels\n",
    " - Interpret the coefficent estimates produced by each model, including transformed and dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`statsmodels` is focused on the _inference_ task: guess good values for the betas and discuss how certain you are in those answers. \n",
    "\n",
    "`sklearn` is focused on the _prediction_ task: given \\[new\\] data, guess what the response value is. As a result, statsmodels has lots of tools to discuss confidence, but isn't great at dealing with test sets. Sklearn is great at test sets and validations, but can't really discuss uncertainty in the parameters or predictions. In short:\n",
    "\n",
    "  - sklearn is about putting a line through it and predicting new values using that line. If the line gives good predictions on the test set, who cares about anything else?\n",
    "  - statsmodels assumes more about how the data were generated, and (if the assumptions are correct) can tell you about uncertainty in the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some terms\n",
    "\n",
    "\n",
    "- **R-squared**: An interpretable summary of how well the model did. 1 is perfect, 0 is a trivial baseline model, negative is worse than the trivial model\n",
    "- **F-statistic**: A value testing whether we're likely to see these results (or even stronger ones) if none of the predictors actually mattered.\n",
    "- **Prob (F-statistic)**: The probability that we'd see these results (or even stronger ones) if none of the predictors actually mattered. If this probability is small then either A) some combination of predictors actually matters or B) something rather unlikely has happened\n",
    "- **coef**: The estimate of each beta. This has several sub-components:\n",
    "  - **std err**: The amount we'd expect this value to wiggle if we re-did the data collection and re-ran our model. More data tends to make this wiggle smaller, but sometimes the collected data just isn't enough to pin down a particular value.\n",
    "  - **t and P>|t|**: similar to the F-statistic, these measure the probability of seeing coefficients this big (or even bigger) if the given variable didn't actually matter. Small probability doesn't necessarily mean the value matters\n",
    "  - **\\[0.025 0.975\\]**: Endpoints of the 95% confidence interval. This is a interval drawn in a clever way and which gives an idea of where the true beta value might plausibly live. (If you want to understand why \"there's a 95% chance the true beta is in the interval\" is _wrong_, start a chat with Will : )\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Polynomial Regression, and Revisiting the Cab Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeMin</th>\n",
       "      <th>PickupCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>860.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>486.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>385.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TimeMin  PickupCount\n",
       "0    860.0         33.0\n",
       "1     17.0         75.0\n",
       "2    486.0         13.0\n",
       "3    300.0          5.0\n",
       "4    385.0         10.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data, break into train and test\n",
    "cab_df = pd.read_csv(\"data/dataset_1.txt\")\n",
    "train_data, test_data = train_test_split(cab_df, test_size=.2, random_state=42)\n",
    "cab_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1250, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cab_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some data cleaning\n",
    "X_train = train_data['TimeMin'].values.reshape(-1,1)/60\n",
    "y_train = train_data['PickupCount'].values\n",
    "\n",
    "X_test = test_data['TimeMin'].values.reshape(-1,1)/60\n",
    "y_test = test_data['PickupCount'].values\n",
    "\n",
    "\n",
    "def plot_cabs(cur_model, poly_transformer=None):\n",
    "    \n",
    "    # build the x values for the prediction line\n",
    "    x_vals = np.arange(0,24,.1).reshape(-1,1)\n",
    "    \n",
    "    # if needed, build the design matrix\n",
    "    if poly_transformer:\n",
    "        design_mat = poly_transformer.fit_transform(x_vals)\n",
    "    else:\n",
    "        design_mat = x_vals\n",
    "    \n",
    "    # make the prediction at each x value\n",
    "    prediction = cur_model.predict(design_mat)\n",
    "    \n",
    "    # plot the prediction line, and the test data\n",
    "    plt.plot(x_vals,prediction, '.-', color='k', label=\"Prediction\")\n",
    "    plt.scatter(X_test, y_test, label=\"Test Data\")\n",
    "\n",
    "    # label your plots\n",
    "    plt.ylabel(\"Number of Taxi Pickups\")\n",
    "    plt.xlabel(\"Time of Day (Hours Past Midnight)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJztnXucVXW58L/PDIMMiAwSeRlF0BTkogxOBocsb2Ue1NC85MkyszjVOZkco6jznrTyJL2kZVn6erpI5THIC6FooIJkOqHiDHIRVBSJERQRUGCAuTzvH3vtYc9mrbXX3nvtvdfa+/l+PnyYvfa6POu2n99z/YmqYhiGYRjpVJVaAMMwDCOamIIwDMMwXDEFYRiGYbhiCsIwDMNwxRSEYRiG4YopCMMwDMMVUxCGYRiGK6YgDMMwDFdMQRiGYRiu9Cq1APnwvve9T4cOHVpqMQzDMGLFsmXL3lbVwZnWi7WCGDp0KM8991ypxTAMw4gVIvJ6kPXMxWQYhmG4YgrCMAzDcMUUhGEYhuFKrGMQhmGUD+3t7WzcuJE9e/aUWpSyoU+fPhx11FHU1NTktL0pCMMwIsHGjRvp378/Q4cORURKLU7sUVW2bt3Kxo0bGTZsWE77MBeTYRiRYM+ePQwaNMiUQ0iICIMGDcrLIjMLIqbMbW5l5oK1vLG9jSPrapl2znAmN9SXWizDyAtTDuGS7/U0BRFD5ja38u37V9DW3glA6/Y2vn3/CgBTEoZhhEbBXEwi8hsReUtEVqYsO1REHhWRl53/B6Z8920ReUVE1orIOYWSqxyYuWBtt3JI0tbeycwFa0skkWGUB9XV1YwdO5bRo0dzySWXsHv37pz39cQTT3DeeecBMG/ePGbMmOG57vbt2/nlL3/Z/fmNN97g4osvzvnYYVHIGMRdwCfSlk0HHlfV44HHnc+IyEjg08AoZ5tfikh1AWWLNW9sb8tquWEYwaitraWlpYWVK1fSu3dv7rjjjh7fqypdXV1Z7/eCCy5g+vTpnt+nK4gjjzySe++9N+vjhE3BFISq/hV4J23xJ4FZzt+zgMkpy/+oqntV9TXgFeDUQskWd46sq81quWGUK01NTdx00000NTWFvu/TTjuNV155hfXr1zN8+HA+97nPMXr0aP7xj3+wcOFCJkyYwLhx47jkkkvYuXMnAH/5y18YMWIE48aN4/777+/e11133cW///u/A/Dmm29y4YUXcvLJJ3PyySfz9NNPM336dNatW8fYsWOZNm0a69evZ/To0UAieH/VVVcxZswYGhoaWLx4cfc+L7roIj7xiU9w/PHH881vfjP0a1DsGMRhqrrJ+XszcJjzdz3w95T1NjrLDkBEpgBTAIYMGVIgMaPNtHOG94hBANTWVDPtnOEllMowwuPaa6+lpaXFd50dO3bwwgsv0NXVRVVVFSeddBIDBgzwXH/s2LH89Kc/DXT8jo4OHnnkET7xiYQT5OWXX2bWrFmMHz+et99+mxtvvJHHHnuMfv368aMf/YhbbrmFb37zm3zpS19i0aJFfOADH+Cyyy5z3fc111zDRz/6UR544AE6OzvZuXMnM2bMYOXKld3nvH79+u71f/GLXyAirFixgjVr1vDxj3+cl156CYCWlhaam5s56KCDGD58OF/72tc4+uijA51jEEqW5qqqCmgO292pqo2q2jh4cMZmhGXJ5IZ6brpoDPV1tQhQX1fLTReNsQC1UVHs2LGj293T1dXFjh078t5nW1sbY8eOpbGxkSFDhnD11VcDcMwxxzB+/HgA/v73v7N69WomTpzI2LFjmTVrFq+//jpr1qxh2LBhHH/88YgIV1xxhesxFi1axFe+8hUgEfPwU2oAf/vb37r3NWLECI455phuBXHWWWcxYMAA+vTpw8iRI3n99UA9+AJTbAviTRE5QlU3icgRwFvO8lYgVe0d5SwzPJjcUG8KwShbgoz0m5qaOOuss9i3bx+9e/fm7rvvZsKECXkdNxmDSKdfv37df6sqH/vYx7jnnnt6rJPJ4ikEBx10UPff1dXVdHR0hLr/YlsQ84Arnb+vBP6csvzTInKQiAwDjgeeKbJshmHEiAkTJvD444/zgx/8gMcffzxv5RCU8ePH89RTT/HKK68AsGvXLl566SVGjBjB+vXrWbduHcABCiTJWWedxe233w5AZ2cnO3bsoH///rz33nuu65922mncfffdALz00kts2LCB4cOL404uZJrrPUATMFxENorI1cAM4GMi8jJwtvMZVV0FzAFWA38B/k1VO933bBiGkWDChAl8+9vfLppyABg8eDB33XUXl19+OSeddBITJkxgzZo19OnThzvvvJNJkyYxbtw43v/+97tuf+utt7J48WLGjBnDKaecwurVqxk0aBATJ05k9OjRTJs2rcf6X/3qV+nq6mLMmDFcdtll3HXXXT0sh0IiiVBAPGlsbFSbMMgwyoMXX3yRE088sdRilB1u11VElqlqY6ZtrReTYRiG4YopCMMwDMMVUxCGYRiGK6YgDMMwDFdMQRiGYRiumIIwDMMwXDEFYRiGAWzdupWxY8cyduxYDj/8cOrr67s/79u3L/B+fvOb37B582bX76644gqGDRvGySefzAknnMCVV17JG2+8kXGft9xyS0nm6jYFYRiGAQwaNIiWlhZaWlr48pe/zNSpU7s/9+7dO/B+/BQEwE9+8hOWL1/OmjVrGDNmDGeeeSbt7e2++zQFYRiGkQVzm1uZOGMRw6bPZ+KMRcxtLlz7tlmzZnHqqacyduzY7srmjo4OPvvZzzJmzBhGjx7Nz372M2bPnk1LSwuXXXZZRsujqqqKb3zjGxx66KEsXLgQgClTptDY2MioUaP4/ve/DyQUyltvvcVpp53G2Wef7bleIbApRw3DiB3FnHZ35cqVPPDAAzz99NP06tWLKVOm8Mc//pHjjjuOt99+mxUrEsfdvn07dXV1/PznP+e2225j7NixgfY/btw41qxZw6RJk5gxYwaHHnooHR0dnHHGGVx88cVMnTqVm2++mSeffJK6ujoA1/VGjhwZ6nmDWRCGYcSQYk67+9hjj/Hss8/S2NjI2LFjWbJkCevWreMDH/gAa9eu5ZprrmHBggUZ23Z7kdru6J577mHcuHGMGzeOF198kdWrV7tuE3S9fDELwjCM2FHMaXdVlS984Qv84Ac/OOC7F154gUceeYRf/OIX3Hfffdx5551Z77+lpYVJkybx8ssvc+utt/LMM89QV1fHFVdc4Rp3CLpeGJgFYRhG7CjmtLtnn302c+bM4e233wYS2U4bNmxgy5YtqCqXXHIJ3//+93n++ecBfFt3p6Kq/OQnP2Hr1q187GMf491336V///4ccsghbNq0iQULFnSvm7pPv/XCxiwIwzBiRzGn3R0zZgzXX389Z599Nl1dXdTU1HDHHXdQXV3N1VdfjaoiIvzoRz8C4KqrruKLX/witbW1PPPMMwdkQE2dOpXrr7+etrY2JkyYwKJFi6ipqWHcuHGMHDmye9a4iRMndm8zZcoUzj77bI4++mgeffRRz/XCxtp9G4YRCbJt9z23uZWZC9byxvY2jqyrZdo5w22WRRfyafdtFoRhGLHEpt0tPBaDMAzDMFwxBWEYRmSIs8s7iuR7PU1BGIYRCfr06cPWrVtNSYSEqrJ161b69OmT8z4sBmEYRiQ46qij2LhxI1u2bCm1KGVDnz59OOqoo3Le3hSEYRiRoKamhmHDhpVaDCMFUxA5YOl1hmFUAqYgsqSYTcIMwzBKiQWps6SYTcIMwzBKiSmILClmkzDDMIxSYgoiS4rZJMwwDKOUmILIkmnnDKe2prrHskI1CTMMwyglFqTOkmQg2rKYDMMod0xB5IA1CTMMoxIwF5NhGIbhSkksCBGZCnwRUGAFcBXQF5gNDAXWA5eq6rZSyGcYhlFsoliAW3QLQkTqgWuARlUdDVQDnwamA4+r6vHA485nwzCMsidZgNu6vQ1lfwHu3ObWksqVUUGISK2IiPP3cSLyzyKSr+XRC6h19tMXeAP4JDDL+X4WMDnPYxiGYcSCqBbgBrEgniTxY34EsAj4EvCbXA+oqq3Aj4ENwCZgh6ouBA5T1U3OapuBw9y2F5EpIvKciDxnXR8NwygHolqAG0RBVKnqbuBTwO2qeiFwUq4HFJGBJKyFYcCRQD8RuSJ1HU00hHdtCq+qd6pqo6o2Dh48OFcxDMMwIkNUC3ADKQgR+SDwGeAhZ1m1z/qZOBt4TVW3qGo7cD/wT8CbjpWC8/9beRzDMAwjNkS1ADeIgvgP4HvAQ6q6UkSOJeF2ypUNwHgR6evENs4CXgTmAVc661wJ/DmPYxiGYcSGyQ313HTRGOrrahGgvq6Wmy4aU/IsJgk6vZ+I9CXh/cnbKSYi3wMuAzqAZhIprwcDc4AhwOsk0lzf8dtPY2OjPvfcc/mKYxiGUVGIyDJVbcy0XsZsJBEZB/waGJz4KJuBL6pqc67Cqer1wPVpi/eSsCYMwzCMCBDExfRb4D9U9ShVrQeuA+4qqFSGYRhGyQlSz9ClqouTH1T1CRHpKqBMRgGJYrWmYRjRJIiCeEJEfgHcQyL19DJgkYicBKCqLxRQPiNEbLpUwzCyIYiCSAYy0msfTiWhMD4SqkRGwfCr1jQFYRjhEbalXirLP6OCUNXTCi6FURSiWq1pGOVE2JZ6KS3/IFlM33Fbrqo/DF+c6FCOvvoj62ppdVEGpa7WNOJBId6JcnzPwrbUS2n5B8li6kz5V0Oiid7xhRSq1ES1s2K+RLVa04g+hXgnyvU9C9tSL6Xln1FBqOqPUv59j0TMYVjBJSshUe2smC9RrdY0ok8h3olCv2dzm1uZOGMRw6bPZ+KMRUVTPGH3VSpln6Zc2nYfBBwVtiBRopx99TZdqpELhXgnCvmeldJvP+2c4T2ODflZ6mHvLxuCzAfRLCLPO/+WAy8Dvyi4ZCUkqp0VDaNUFOKdKOR7VkovQNiWeikt/yAWxMUpf3cAm1V1b4HkiQSl1NiGEUUK8U4U8j0rtRcgbEu9VJZ/kCD1aaq6zvn3uqruFZEbCy5ZCTFfvWH0pBDvRCHfM/MChEPGbq4isgD4jarOdj7/DBigqlf6blgErJurYRhupMcgIGGd2EAvQWjdXIELgQed/kvnAm1RUA6GYRheJJVAudVYFBtPBSEih6R8vBJ4EHgK+I6IHKKq7xZaOMMwjFyxjL388bMgVpHotSQp/3/S+ackJvYxDMMwsiQuFeSeCkJVjy6mIIZhGJVAnLoqB6mD+LKI1KV8HigiUworlmEYRnkSp04NQdJcv6yq25MfVHUb8JXCiWQYhlG+lLpGIxuCZDH16O4mIlUkmvYZWRIXv6NhGIUjTl2Vg1gQj4rIPSLyURH5KHA38FiB5So7yrVzpWEY2RGnrspBLIhpwFeBqc7nR4H/VzCJyhSbzc0wSkcprHevY8apRiPIjHKdwM+df0aOxMnvaBjlRCmyhjIdMy41Gn6Fcveo6uUi0kyi7qEHqjquoJKVGXHyOxpGIQhjFJ/LPoJa72FaGV7HvHZ2CzMXrI2sxZCOnwUxzfn/Yp91jIBYh1ijkgljFJ/rPoJY72FbGX6egSjXPaTjGaRW1Y0ich5wPjA0paPrOlVdVzwRywPrEGtUMjfMW5V37n+u9QNeVnpd35ruGeeum7M81NqETJ6BqNY9pOPnYvo50AA0AZ8VkftU9YdFk6wMiYvf0TDCZG5zK9vb2l2/yyYGl2scz816r6kWdu7pYNvuhFydHl2tc40Ruh0zrH0XEz8X0xnAWFXtEJF+wBLAFEQArN7BMPbjN1LOJgaXaxzPLWto194OT6WVq3xex3STOZ99FxM/BbFPVTsAVHWXUyBnZCBOfVYMoxj4jZSzicHlE8dLt96HTZ+fcZt8Y4TJY3rNTRGH+KOfghghIs87fwsw3PksgFoWkztW72AYPfEa+Q/sW5PVOxFm/YCXTNUidKnmbfmnexE+dUo9i9dsiZ1XwU9BjCnUQZ3mf78CRpNIof0CsBaYDQwF1gOXOn2fYoXVOxjlSD5uU6+R//Xnj8pajrDieF4yhZE44uZFuG9Za+B9R8lF7ZfFtM7vX57HvRX4i6qOAE4GXgSmA4+r6vHA487n2GFz4RrlRr5tYqKYwVdImfLp1hq1ljxBWm2EiogMAD4CfB5AVfcB+0Tkk8DpzmqzgCeAbxVbvnyxegej3MjVbRrWSDjofrI9XqGyCvPxIkTNRV10BQEMA7YAvxWRk4FlwNeBw1R1k7POZuAwt42duSimAAwZEr1J7eLUZ8UwgpDLD15YyRpB9xOl5JB8uiZEzUVdisykXsA44HZVbQB2keZOUlXFpb2H892dqtqoqo2DBw8uuLC5MLmhnqemn8lrMybx1PQzTTkYsSYXt2lYk+IE3U+UJuHJp1tr1FzUngpCRO5x/m8WkedT/jWnZDflwkZgo6oudT7fS0JhvCkiRzjHPAJ4K49jGIYRErn84IU1Eg66nyiNvPOJb0StFXjRezGp6mYR+YeIDFfVtcBZwGrn35XADOf/P4d5XMMwciMXt2k2bpb02MEZIwZ3p4RWibhWOafuZ25za6D1ikmu8Y2ouahFPUrMu1fY/0Oeuuw0VX0y54OKjCWR5tobeBW4ioQ1MwcYArxOIs31Hb/9NDY26nPPPZerGIZhFAiv4rD0kbTbeplI3Y/f9mGlrZYjIrJMVRszrRckSH2/iPxaVW8RkYNIjPD/CfhQrsKpagvgJtxZue7TMIzoEHQk7BY78GNg3xquP39Uj/27bV8tYsohBIIoiA8BPxaRvwGHAH8ioSAMwzA8CeJmyTZGsKe9K9D2XaqmHEIgiILYA2wDBgB9gRedWeYqkihVORpGXPB6b7xiFV6k1wTYRFyFJUia67MkUk5PIVHgdpWI/LGgUkWUqFU5GkYc8Htv3LJ2MpFqNUQt66fcCGJBfDklJbUVmCQiVxVQpsgSdpWjWSNGlAnr+fR7b56afmb3OulZTEHaZEct68ePOL7vGRVEUjmIyKFAH2fxgkIKFVXCzLWOUuWnYaQT5vOZ6b3xilUEbZMdh4m44vq+Z3Qxicg/i8hLJArcljr/Lyq0YFEkzCrHKFV+GkY6YT6fXu9HlQjDps9n4oxFrm7aZMHZwL413csO6hXPaWni+r4Hudo/BCYCa1X1aOAcIOcaiDgTpr8zSpWfhpFOmM/nGSPcW+J0qgaK5aVmLm1va49l3C+u73sQBdGhqluAKhERVX0UOLXAckWSMFsER63nSiUwt7m1e5J6r1GrkSDM53Pxmi0Z1/EaTcd15J1OXN/3IEHqHSJyMPA34Hci8hYQbbVXQAo9YYllXxSGuPqAS0WYz2fQUbLbenEdeacT1/c9iIKYTEIhXAt8jkQ9xPmFFKoSiFP2RTkQtT77Ucfr+QSYOGNRVs9s0FoHt9F0rnUOUcsYiuv77tmLSUQWqurHiyxPVlgvJiMow6bPd+0fL8BrMyYVW5xYErS/UpDt0vHaTy7HzFXOSiJoLya/GEQ0J1swjCxJdvt0I+o+4CiRazzALXZ3xfghgWJ56dvW1dbQp6aKqbNbPONI5RK3iAJ+LqYBInKR15eqen8B5DGMUEmOJt1aQcfBBxwl8okH5BO7S24bNI5UDnGLpqYmnnjiCQYNGkRzczOtra3069ePa665hgkTJhRNDl8FAZxHwgpPRwFTEDkQNd9ouVPJ3T7DftZK3fcoaBxpQG0N29vaD9g+6tZiU1MTv/vd71i1ahVPP/00nZ0HPrcPPPAAixcvLpqS8FMQr6vqF4oiRYVgmTTFp1K7fRbiWSt1Jk4Qy2Bucyu79nUcsE5NlUTKWkwqg82bN9PR0cG2bdtoamqiq6vLd7t9+/bxxBNPREJBuDttjZy5Yd4qy6TJk2xHxaUe9ZaKQmRtuWXinDFiMDMXrGXq7JbQLOJsO7+m3suZC9bS3nmgO/HgPr263VTFtuBTlYGq8t5777FkyRJXCyETvXv35vTTTw9fSA/8FMRniyZFBTC3udXV7IV4+UZLSS6j4lKPektFofzwqbGEQlgpfvsMci+9zm/77vaiWfCpCmHv3r0sXLgwJ2VQXV3Nddddx7vvvsvmzZs5/PDD+dznPheNGISqriyaFBWAXwZFuY9mwyKXUXFc88/zpRiWU9D7kc2oPdvOr+n78jvvXK0qL/nnNrfy3Tvv57W/P0LXrm1U9R1An6ou3m55DDJM5exGTU0NkyYlUq5LoQzcCFIoZ4SA38it3EezYZHrqDgO3T7DphiWU9CYQDaj9lw7vybxO++ps1uyOo90+fe2vsgLCxbx2d9u54RhR7Hu7TZ2LJsPKRU2Oz331JNUZQDRUQjpeCoIEXlcVc8SkR+p6reKKVQ5kRx9eI0nBvatqbgfr1yp1HhCrvSpqer+oayrreGGC0aF+qwFjQm4jdqvm7McOFBJ5HuP/SzGmQvWZrXvpqYmvjz1h+za24nUHMR7z/6ZpDJ4/qVA4gDxUQZu+FkQR4jIPwEXODPI9Qhaq+rzBZWsDMhUQVpbU831548qslTxpVLjCdni9tzt7fDPjsmFfGICnaqulkQY99jLyvDbdzJuANDQ0MC9997LY489hleniYxIFbVHjeQjpzZw/XVfiYUycMNPQXwX+C/gKOCWtO8UOLNQQpULXjn4kMjD/9Qplef6yIdKjSdkS7H6TgW5H359mNxkKuQ9ntxQz3Ovv8Nv71/IuyseR4APj/8gv/7uL5g/f35eyqB3/Yn0ft8Qeh92LF1t79FnyBgOqj+R9+pqY6scwKcXU/cKIv+lqj8okjxZEfVeTF79f5JYfxijEESp71QmK7oYMiWrkjfsqub3f3qAXS8tBd830wfHMjhx5Im8UX0Ee3Zu71YGrqsTzV5fQXsxBZly9AcicgHwEWfRE6r6UL4CVgKZulhaDUT2VHIleuq5D6itQSSRvpl+HQodq/HL6vG6N9fNWe7a7iQbmYLc+/QWFcuXL2fp0qUZC9C8qKqqovEjH+ftuhN5552tHD2yke9PuajH+fq943GPj2VUECJyE4kJgu52Fn1dRP5JVb9TUMnKADefZzpWAxGcSq5ETz/31Jqa9OtQyFiN1z147vV3uG9Zq++9yUcmt+Ne+7M53HfwW5w2ZhjNzc2+LSqCUFVVxQUXXMC5555Lc3MzgG8w2a8mJNvziypB0lwnAWNVtQtARGYBzYApiAyk+lO9Rhn5jjAqaUSdr2+9UNeqGPfAL54FPa9DIf34XvfgnqX/OMBCCFOm5HH3tr7IzpWL2Pf2Bva1vsjr2sUfcjoTofb4D1F77Cm0v/kqnxl/jKcyCHJ/k/GN5HXIFGPMtM+g1mKhCVoHUQe84/w9oECylCVenSgh/xFGpY2o86kOLtS1KtY9CHKOqesUqvbDLyspbJlSK5KbV2yic+9O9m1cTS7xg+rqavo2Tkb37gbg4NFn9ogb3O4RJwh6f+c2t3Lfstbu69Cpyn3LWmk85tCMc1yk7zMba7HQBFEQNwHNIrKYRMzlI8D0gkpVhhRiVFdps6R5+darRJjb3Op7zkGuVS6WQLHuQZBZ2Yoxy5qXHNUiGWMMmY6fVAibNm1i9+7dLFq0KNQWFd9Y0uYqe73HdZvb3OoaO3G7v9k8B5nWzcZaLDRBgtT3iMgTwAedRd9S1c0FlapMCXtUVw5977PBK6bjlVOfitePa3J5rpZAse5BpnhWJms0LEvnjBGD+cPfNxywfPyxA3l+ww5PCzn9+K+uep6r/nQzMw7pYtSxR7J7925mz56ddappVXU13wjYr2han+BWvN88InDg/c3mOci0brbWYiEJ5GJS1U3AvALLUhGE6a+uhMri9Ov1qVPqM/q73fAa4VY7M83lagmEfQ+8no90H7cI1Paqoq29K6MP+8i6Wnbt7QjF0lm8Zovr8vVb27jpojGusicrkt99522q+9ahXZ3sWvEYoCwFlj6RxQWqqqb2uA/Sp1c1p448NqsitGyseLfOy6mk399snoNM64ZhLYZFyXoxiUg18BzQqqrnicihwGxgKLAeuFRVt5VKvkIQtr+63CuL3a5Xqp83Hb9Rldc2yeW5WgJh3gO/5wPoce6qoAg/uWxsIB+3F9mORP2uU1KRJV1FC+6Exb17c9ttt+WUZlqIFhVBrHi/zsvgfn+zeQ4yrZuvtRgmpWzW93XgReAQ5/N04HFVnSEi053PsekBFcQyCNtfXW6VxenXcPc+91FvJn/33OZWvvfgKrbtTrzkdbU1DOxb0/05lfoMo7ZMI7Uw74HX8/G9B1fRt3evvHzcXhxZV5uVVZt+nZJZRf16V3P77RuYM2cOS5YsyakqWUSoqqpi4sSJjBw5smT9ivw6L3vNRJjNc5Bp3fTvS5nF5FtJ7YzyV6nqiFAPKnIUMAv4b+A/HAtiLXC6qm4SkSNIFOT5qsmoVFJ7ZSilP0hRqnCNGpkqbtOpral2vd4A0+5dfsCkMVVAdbX0WJ56j4Lew0KSqfLeDbdnJ+h+aqqEy049ukf9Anifd1NTE9+7+XaWvraVqsHD2PXS39n72rIsJU4VPtGiou/7j+HT536UIf06Of3000vemsLv+v3UxWKLI6FUUqtqp4isFZEhqnpgZCp3fgp8E+ifsuwwJ9YBsBk4LMTjFZSglkFY/upyrH3IZtRb75yz2zWYOGOR64xiXYB2KgP71riOxHKxBIo15zMEyxIKsp9UDu7Ti8Vrtng+u4ft2dBdlfzQQw8xf/78nFxFScvghJMa2aiHUpPWrwjghYNruX16NNq7eV2/fDovx/WdDeJiGgisEpFngF3Jhap6QS4HFJHzgLdUdZmInO62jqqqiLgqcRGZAkwBGDJkSC4ihE5Q/3UY/upyrX0I6gtPXi8vX7LffhTY097l6reH7LLMCjXn87UecxZ0qrpaTUF93G5s393Odsfttrf1RfZsWEFVbX/2vvkqmzav48P/+UpeLSqSVclbt27ttgy8RudRyrzzek9z7bwc53c2iIL4r5CPOZFEC/F/BvoAh4jIH4A3ReSIFBfTW24bq+qdwJ2QcDGFLFtOBLUMwvBXl2vtg9c1rKutod9BvfKegzpJWNeqUHM+3zBvlWuTgwlyAAAgAElEQVSA1M9qcttPUsY3trdRlWZ9JJXBoYcOYteml9n2j3Xs27QWNH9lkKlFRRwy78KO7cX5nQ1SB7FERI4BjlfVx0SkL1Cd6wFV9dvAtwEcC+IbqnqFiMwErgRmOP//OddjFJtsLIN8ayHKtfbB6xqed/IRnqmVXvtxi0Gk4natUl0AdX1rUIUdbd5BQa/r3bq9LWd3wtzmVkQOXJ7JanIjdd0Zd83jlt89QGfvfux+dRl7XnkGtIvtgfbUk2z7FaUTduZdoVw3YdYs+T0rw6bPj7TLKUizvi+RcOkcChwH1AN3AGeFLMsMYI6IXA28Dlwa8v4LRjGzieIwAssFt2t4xojBGRvAee0nNYspnfRrle4CSN3O65h+lsq0Py2nvUsDy+wmQ5JsZ4ILu5tpalUyZKcM3AjzXYmL68bvWVGiKzcEmw+ihUQ316Wq2uAsW6GqY4ogny9RyWIqJtlm28Q1OAYwccYiz9YITwUIaAa9Vl7H8Tvm3OZWps5uCZx15CezV0sHSARGm7/7cdft0pVBvt1MvVpUlDqryIt8n49ikU2GXiGmhnUjtPkggL2quk8c21dEepHzbBtGvmQzAovLCMuLfN1pQa9VLq0NJjfUewaUg2yfJFNLh22723v0mUoWoa1evZqnnnqqYpSBG3Fxt6Y/h34/ntvb2pn2J/f5uktBEAWxRES+A9SKyMeArwIPFlYsw4+g/tG4BseSVo/Xi5SNOy3ItQqSFlrXt+aAZfUB00mTx0iSatWlB5BTSRahfeb+bagqvTrb2Pn6SjQHd1HYrqIoECd3a+pzmMlibe/SyLyjQRTEdOBqYAXwr8DDwK8KKZQRDpka1EWRTOZ4IdoM+KWXJtm5p+OAjrFuAdeaagGlOwaRLnP6+SWVQ1IZdO7aBgpdHXvZ+/ry3DKLpIr+p16I7t1N565tHNT/UL71tX9l+udzykyPLHFtNRMkDTkq72iQLKYuZ5Kg5ESuazXn2b2NYpKpQV0U8SuYq88hhhJ0YpZMuI3qvFxYbstS102d+KZz1za0q4s9ry4Dzb+1ddMbHcgJHz1gjuQHN9eWXY/+uLaaScrnFXeC6LyjQbKYJpHIWlpHorJ/mIj8q6o+UmjhjPzI1KAuinj5jwWyDjxmOzFLLrJ5ubBSlzU1NfGVr9zI5s2beeG1vah2suuFR8kplOd0Mz1n1OGucYOh0+e7bhaVEWnYhN1Cv1gkZfYrjIwCQVxMNwNnqOorACJyHDAfqAgFEecsIC8fudcEKVEgTL9yphhMppbOuciQ7Ff0zOpXaT/oEA7uV8ubT89Fc3EVOcogSXW/gRw8+kyOHTWOBzyUpZfVKJLwfcfxOS5XMhVGRoEgCuK9pHJweBV4r0DyRIq4ZwHF0Ucbpsx+WS5BWjoHkSGZVQTQv39/fnzzzT2CyDuDCuuhDNJdRZmuhdfIU3W/FRG357icueGCUZF+Rz0VhIhc5Pz5nIg8DMwhYRNfAjxbBNlKTlyzgJLE0Ucbpsx+1ohf3MGrrcVhezbwla/cCEBDQwNz587lL3/5S06trYHubqa93zfEVRn0WNWRO9O1CJpZFafnuJgU22MQ9XfUs1BORH7rt6GqXlUQibKg0IVy1p473vgVyvkVuSVbOqcWos2fP5+HHnoo54rkVGXQ26WbqR9XjB/CjZOD1aVmE1ex57gnUWj5XizyLpSLggIoNXHIs45zjKTQ+I3OZi5Ye8DEN3s2rODgAQO5479nc8XSZ9nVujbhm8kKAZGclUE6XsrBb2rS9HPetbfD1Z0Wpec4CsTdY1AIgmQxDQO+RmIq0O71c233HSei7sOPe4ykGLhluTQ1NXFs66O8+upudr7xMvu2rGffG2u7G9htzPoowqmnn8PVl1/Ikyte48md74fDTshL7kztU/zue/o5e42Mo/IcR4W4VGYXkyBB6rnAr0lUT+doX0cXvxF41P2DNuIJTjKYnG+/IhBqj/8Qtceewr43XwXg4NFn0mvUOKZMOZMp9HymBtTWsKOtPeuEVj+3htd9v27OcqbObondcxwV4uAxKDZBFMQeVf1ZwSUpAUFG4FHOs7YRjztJZbB582Y6OjrYtm0bTU1NucUPUqqSe1UJfUae4eoqSr3myWdmbnMr0+5dnlPjMr9nzuv+JjOY4vYcR4WoewxKQRAFcauIXA8sBPYmF6rq8wWTqkjEfQRuI56eykBVee+991iyZElOFkJ1dTUHN06m02lR4ZVq6obbNZ+5YK3vvBSecogc0NYj/ViZMpXi9BxHhWwbYVaCRRZEQYwBPgucyX4XkzqfY03cR+CVOOJJVQh79+5l4cKFOSsDt26ml//5naz35XXNc32OOlV9Y0lBpxSNy3McJYJYWpUU+wuiIC4BjlXVfYUWptjEZQSeTcZKOY1kUpXB+9//fvbs2cPvf//7nOoOampqmDQpkdLp19q6fol7p02/vlap8YKgnVoz4WcBZJpSNEnUnuNyoRSeh1JZLEEUxEqgDo85ouNMHEbg2WasxJVUZXD44YdTVVXFHXfckVPcIFUZgL9CSMfrmfjUKfU9ZrdLLk9XDm6dWnPFzwJIve+WpVRciu15KKXFEkRB1AFrRORZesYgYp/mGocReNzjJF6ktqjo27cvP/3pT4uuDNzweyYajznU91nx6kRbJdCVg64IagHE4TkuJ4rteSjlb0AQBXF9QSUoMVEfgcc9TgI9lUFDQwP33nsvjz32WE6uIhGhqqqKiRMnMnLkyIJMfOPXoTWX7KIuPbC3UyaytQCi/hyXE8X2PJTyNyDIfBBLCi6F4Ulc4iRJ0pXBgw8+yPz580NRBg0NDWzdupXTTz89krOhed2rapGslEN6XMOIFrlYbOkxhDNGDGbxmi2Bti/lb0CQSur32N+4vjdQA+xS1UMKKZiRIOpxktR+RQ8//DAPPvhgTq6iuCkDN7zuVTbKAaBL1ZRDxMnGYnOLIfzh7xu6v88UUyjlb0AQC6J/8m8REeCTwPhCCmXsJ0r+5VRl0NzczPLly1m6dGnODeyqqqq44IILOPfcc3lyxWss7ziSDQOOpaOulnM+OJwpMfiRTB8ZfuqU+gNGhul9n5J4ZUZlGhnmMxrNtC+LXYSP3yyJSbLJWivmffLs5uq7kUizqjYUQJ6sKHQ310omXRnk26IiVRk0NzcDdMcP4tpFM6jcXusFyYwKcsx0gl67uF73uOHVFTqdYnbXzbuba8qOLkr5WAU0AnvykC0WVOLIKhk/WL16NU899VRoyuC1LbtYVzeO5vcdT/OrMPCIoVx//igmpM3TnEqUM7WSz4abVeAmdz6ZUelkOxr1e47jdt3jSpDK9+R6USNIFtP5KX93AOtJuJnKlkqolEytO+js7GTHjh05K4XUqmSgR2bR3OZWpv1pOe0peZ7bdrcz7d7lQOJ6xilTK8gIPtu5q7N5poLOLZ2cNc/vOY7TdY8zQSrfoxRXTCVIDKIi5oXIVAHb1t7J9x5cFUurIr1f0e7du1m0aFGoLSq8AskzF6ztoRyStHdq90g1TplaQUbw2cqdjbXqFbdwkyGThRCn6x5n3CzIfOJGxcRvytHv+mynqvqDAshTEoJWwG7b3c623YmJV6JsVaR3M33kkUeKogzc8BuNJr+LeqZWKplG19nKna21GkQ5JGWYOrvF9fs4Xve4E9c6FT8LYpfLsn7A1cAgoGwURJBRoRtB/LWFjmUklUHzmvWs392LnW172bXiMcihyXTQfkXZ4Od/TY5Uo5SplYm6vjXdg4R06nOQ22uU72Wtes05XS1Cl6rvrHlJ4njdjdLgN+Xozcm/RaQ/8HXgKuCPwM1e28WRfHyuftsWIpaRWojWu3dvbrvttki0qPBi2jnDD4hBANRUS4+RahxGWHObW9m5p+OA5TXVwsyLT85Jfq/nx8ta9Rr1u2UeBbEQ4nDdjdLhG4MQkUOB/wA+A8wCxqnqtmIIVkwyZRlUi9C/T6+s5/XNN0skVRmcdNJJzJkzhyVLlmRdlVwsZeBG8jxvmLeq+/oN7FvD9eePit0Pk1c8pV/vXjmfS9AMl7b2Tm6Yt4qW6z/eLUumUb9ZCEa++MUgZgIXAXcCY1R1ZxgHFJGjgd8Bh5Hwg9ypqrc6ymg2ibmv1wOXFksZZcoy6FLlhgtGZe2vzSZLJL1FxQMPPMCCBQtyalEBgFTRu/5EvnDeaUVTBl6UyyjV637ucBk4BCXo3A4A29vauycSCno9y+XaG6XBz4K4jkT31v8D/GeiiBpI1HNoHq02OoDrVPV5x3W1TEQeBT4PPK6qM0RkOjAd+FaOx8iK5At03ZzlnpWtuYzG/LJEUgvRHnroIebPn59ziwpF6F1/Ir3fN4Tehx1LV9t79BkyhmNHjeP26bGf1yky5Jr1k+2857v2drhaq8n1ovyDX4n1Q+WMXwyiqhAHVNVNwCbn7/dE5EWgnkRtxenOarOAJyiSgoD9L6qflZDtaCw5Oty+fiV7NqygqrY/nW+9Su99m/jwf74QSouKrVu3IkeMYta63paNUmByyfrJZd7zuc2tXJshAymKVEL9UKURpFCuYIjIUKABWAoc5igPgM0kXFBFJQyfbaplcP/Cv7HhmWXs3rgGdL8y2JGFTH4tKlIZYSO3gpPL85FLHGpyQz3fe3CVa7ZUlGsUrDK7/CiZghCRg4H7gGtV9d0UFxaqqiLi6nwXkSnAFIAhQ4aELlcuPttk/KCQ/YoKIbeRPdle51yrla8/P/uYV6mxyuzyoyQKQkRqSCiHu1X1fmfxmyJyhKpuEpEj8JjiVFXvJBE4p7GxMb85HXMgtQht3759bNu2LeeOptXV1Zx/xb/StGYDu/Z2Mmz8uVw55aLY/tCb//lAco1bxDEDySqzy4+iKwinZfivgRdV9ZaUr+YBVwIznP//XGzZ0klvUfHuu+/y17/+NTcLQarof+qF6N7dnD30IA4//HCO+dC5zFrXmz6Hd9IHeBdi67M1/7M7+VQrx80qtMrs8qMUFsRE4LPAChFJRuK+Q0IxzBGRq4HXgUuLLViqQti7dy8LFy7MuUXFYRMv5t1336Vz1zaq+w3k4NFnclD9idTX1fKAk1k0ccYi2tp7jrji6rP1qwiO27mESRwtgVyppHOtFIquIFT1byRSZd04q5iyJBVCZ2cne/bs4Q9/+ENOdQduLSre7DMk42iqnHy2fhXBydz9SiVulkA+VNK5VgIlzWIqJU1NTXz4tNPoytJCyLYq2W80VU4+W7+KYD+LyOIWhhFdKlZB/PJ/52VUDvm2qMg0mionn+20c4ZnnbtvcQvDiDYVqyCWdxwJ1b2gM635mlTxkdM+zMiRIwveoqLQPttijs4nN9T36LeUSl3fGtdtvOIW185uYeaCtd3ylpOVUU7nYpQ/Oc1JHRXymZN62PT57Gl9kZ0rFwH0aFGx6fffyHp/UXvxSzHf8NzmVqbdu5z2zrTOrVXCzEsO7Haaaa7eXOdtLgVB7n+29yToMxW1Z8+IPkHnpC5IO404cGRdLQfVn8igc/6NQef8G/3HnsuACZdy7KhxWe8r+eK3bm9D2e8qmdvcGr7gAfGrai0Ukxvq6df7QKO0vUtdj5sp1tLW3sk9S/9R9PPIlqD3P5t7EnSfUXz2jPKhYhXEtHOGU1tT3WNZrv7/UvwYZyKXDKm5za1MnLGIYdPnM3HGopx+ZLw6m7oFsKedM5yaaq+EtgReM6hFKdMr6P3P5p4E3WcUnz2jfKhYBTG5oZ6bLhpDfV0tQmI2sFzdFlFMV/UanXstD2sk6rV/cY5xABk8nNXirkCilOkV9P5nc0+C7jOKz55RPlRskBrCy9kOkq6a9BO3bm/rnng+lykq0/fn5XfONkMqrEZrZ4wYzB/+vuGA5cqB6a5eE/CkyusWgxDnOFEhaLpyNvck6D7LKVXaiB4Va0GESSZ3VeroHPa7TXIdpQcZ7WdrIYUxEp3b3Mp9y7zPJejoF/bLe+PkMXzqlPoelZUK3LesNTJ+9qDuymzuSdB9hukqNYx0KtqCCItM6apuo/MkuYzSg472s7GQwhiJ+p2n2768jllfV8tTKRMdLV6z5QBPVJRakmSTrhz0ngTdp7W3MAqJKYiQ8HvxM43Cs/UXF8LvHEbRnt/xvUa/QY4ZBz97IVpMZKNMTCEYhcAUREjMbW7tMclLXW0NN1wwiskN9dT1rXGd/CVJlQjDps/POPpLxh28vPZVIjn3PUpuk3oOB/UK7oGc29xKlRNbSadaxNWV4jX6hUQjw+Qyr+tnfnbDDasLCQ9TECHgViC2va2daX9aznOvv8POPR0+Wx8Yk4ADW024FVm57SffVhV72vfPa7G9rT3Q/pKyuSmHTEVtbtNtprffqKkSaqqlx/U1P7vhhrVvCRcLUofAzAVrD6gehkSB2D1L/+GZqeOWwpmew56sTbh2douvcvDaPhtyyamf29zKdXOWu8pWJWSdOuwmQ3uX0q93r4zB3TDqOIx4Y3Uh4WIWRAj4+cK9Cr0E6MpQBBbEashWnly2y9Rsz+scfTJYs5ZhR1s7Ldd/3HM7GzkaEI94VZwwBRECfq2uqz388l7+eoABtYnmdpmygrxQ4LhvPxyo1iLVX+sl05F1ta5+3SDy3TBvVVb+4FyzqcKq4zDijdWFhIu5mELAq2VETZVw+YeOPiBPHbwtC4Bd+zqY29yacdRTUy3UVLlXGgeptUivp/CKIZwxYrBr3YWXUkxle1t7VtXZueb128jRAKsLCRtTECEwuaGemRefzMCUttZ1tTXMvORkbpw8pkdxlH/noQTtncoN81ZR5dFmAhJ++JkXn8zMS06mPkDTu2tntxzgl89kAdTV1nDTRWNYvGaL6+g8FzL5g3NtgZJtaxGjPAmzhY5Rwe2+S8Hc5lbPSXWy4YrxQ7hx8pgeyzK1zk6SmlWUaZtkm+6ps1sC7TsoArw2Y1LG9bKhFO3NDSOuWLvvCBJWJsVDyzcdsCzoSDl1BJ9pm2Sb7rBH4YUY1dvI0TDCxxREEQnLH769rf0AP76b7zWTHEG2eWN7W1b7zkQh/cGTG+p5avqZvDZjEk9NP9OUg2HkiSmIIuI1cu7Xu7rHyHegxxSdqVw3Z7lncz7wbpOdKsfkhno+dYr/j2iVCFNnt9Cnpoq62sxy+eFVUW0YRjSxNNci4tV76L8vHONbTeyGW9V0pqrk5PFSu8z6dV9NHgdg2+52amuquWL8kAPabwfB4gGGET/Mgigi6X7yutoa+tRUMTUtwyjdGvAin4wgvwpoADcDpK29k8VrtvTY58C+NdTV1iB4Wy3FtBysmtowwsOymEpE0KybTNZELhlBQfbp91Ss9zieV1ZUIbKW3LBMJsMIhmUxRZygPWOSVkCYU28GmbfBL4bhNTIvdS2C9eExjHAxBVEisqn8ndxQz82XnhxahWiQeRv8Kr29KqJLXcVq1dSGES6mIEpEtqPtTPGETH731HW8KrRTYwW5xD9KXYtQagvGMMoNy2IqEbnM4OY2c1iQLqbp6wSZt8FNvnS8rJ1S+fvDmBXPMIz9mIIoEWHNJRyki6lXzKFahC5V12OnbuvVlC9qI3Obn9koJ6IwM17kFISIfAK4FagGfqWqM0osUsEIY7QdxO/utU6Xqm92UVK+TPUUUcLmZzbKgajMbxKpGISIVAO/AM4FRgKXi8jI0koVbYL43fP1zZc6tmAYlUZUMvKiZkGcCryiqq8CiMgfgU8Cq0sqVYQJ4ncPwzdvI3PDKB5RyciLmoKoB/6R8nkj8KESyRILgvjdzTdvGPEiKjPjRU1BZEREpgBTAIYMGVJiaaJBkNG9WQCGER+ikpEXqRgE0AocnfL5KGdZN6p6p6o2qmrj4MGDiyqcYRhGMYhK3C9qFsSzwPEiMoyEYvg08C+lFckwDKP4RMHqj5SCUNUOEfl3YAGJNNffqOqqEotlGIZRkURKQQCo6sPAw6WWwzAMo9KJWgzCMAzDiAimIAzDMAxXTEEYhmEYrpiCMAzDMFyJ9ZSjIrIFeD3P3bwPeDsEceJIpZ57pZ43VO65V+p5g/u5H6OqGQvJYq0gwkBEngsyN2s5UqnnXqnnDZV77pV63pDfuZuLyTAMw3DFFIRhGIbhiikIuLPUApSQSj33Sj1vqNxzr9TzhjzOveJjEIZhGIY7ZkEYhmEYrlSsghCRT4jIWhF5RUSml1qeYiIi60VkhYi0iMhzpZankIjIb0TkLRFZmbLsUBF5VERedv4fWEoZC4HHed8gIq3OfW8RkX8upYyFQkSOFpHFIrJaRFaJyNed5WV9333OO+f7XpEuJmfu65eAj5GYte5Z4HJVrYipTUVkPdCoqmWfFy4iHwF2Ar9T1dHOsv8LvKOqM5zBwUBV/VYp5Qwbj/O+Adipqj8upWyFRkSOAI5Q1edFpD+wDJgMfJ4yvu8+530pOd73SrUguue+VtV9QHLua6PMUNW/Au+kLf4kMMv5exaJl6is8DjvikBVN6nq887f7wEvkpjOuKzvu89550ylKgi3ua8raT5OBR4TkWXOFK6VxmGqusn5ezNwWCmFKTJfE5EXHBdUWblY3BCRoUADsJQKuu9p5w053vdKVRCVzodVdSxwLvBvjjuiItGEj7VS/Ky3A8cCY4FNwM2lFaewiMjBwH3Atar6bup35XzfXc475/teqQoi49zX5Yyqtjr/vwU8QMLlVkm86fhrk37bt0osT1FQ1TdVtVNVu4D/oYzvu4jUkPiRvFtV73cWl/19dzvvfO57pSqI7rmvRaQ3ibmv55VYpqIgIv2cABYi0g/4OLDSf6uyYx5wpfP3lcCfSyhL0Uj+ODpcSJnedxER4NfAi6p6S8pXZX3fvc47n/tekVlMAE6q10/ZP/f1f5dYpKIgIseSsBogMeXs/5bzuYvIPcDpJDpavglcD8wF5gBDSHQDvlRVyyqg63Hep5NwMyiwHvjXFJ982SAiHwaeBFYAXc7i75Dwx5ftffc578vJ8b5XrIIwDMMw/KlUF5NhGIaRAVMQhmEYhiumIAzDMAxXTEEYhmEYrpiCMAzDMFwxBWEgIoNSOj1uTuv8+HSRZbnHaQkwNW15akfKl0XkfhEZGeJxf5qsKBeRJ0SkMeW7oaldUQuNiHxeRLY457paRL6Uwz7qROSrPt+riPwh5XMv55gPOZ8v8OpyLCI7Axz/V5nuj4jcJSIXuywfKiL/kvJ5jIjclemYRviYgjBQ1a2qOtZpv3EH8JPkZ1X9p2LJISKHAx9U1ZNU9ScuqyTlOh6YDSwSkcEhHHcQMN5pcFdQnE7CQZjt3I/TgR+KSLZ9g+oATwUB7AJGi0it8/ljpHQTUNV5qjojy2N2o6pfzKM78lCgW0Go6grgKBEZkqs8Rm6YgjB8SY4WReR0EVkiIn8WkVdFZIaIfEZEnpHE3BLHOesNFpH7RORZ599El332EZHfOts1i8gZzlcLgXpn5Hyan1yqOttZ/1+cfX7XOd5KEblTEhwnIs+nHPf41M8pfAr4S8Dr4Sq7M+q/LWW9h0Tk9OQ1FJGbRWQ5MMG5dqsdS8m3BbPTDmUdcIyInCoiTc5xnxaR4c7+Rzn3ocXZ5/HADOA4Z9lMj90/DExy/r4cuCdF/u7zkUTHgSbnnG9MWed0x9q6V0TWiMjdIiLOd91WmIhcLSIvOTL+T+p1Aj7inMurKdbEDOA0R/akJfkgiY4HRhExBWFkw8nAl4ETgc8CJ6jqqcCvgK8569xKYqT/QRI/vL9y2c+/keiXNobED9MsEekDXACsc6yEJwPI8zwwwvn7NlX9oDP3QS1wnqquA3aIyFhnnauA37rsZyKJ3vmp3O38QLWQ+CHNJLsf/YClqnoyiRbMFwKjVPUk4Ea/DSVR+X4s8AqwBjhNVRuA7wI/dFb7MnCrY3E0kuhOPJ3913Kax+7/CHzakf8k9nf+TOdW4HbnnNMrcBuAa4GRjpw9BgQiciTwX8B457sRadsfAXwYOI+EYsCR/UlH9qQl+RzgO2gwwscUhJENzzo95/eSGNUudJavIOEWADgbuM35YZ0HHCKJ7pKpfBj4A4CqriHR9uCEHOSRlL/PEJGlIrICOBMY5Sz/FXCV49q5DPhfl/0cAWxJW/aZFLdb6gxcucjeSaKBGsAOYA/waxG5CNjtsc1lzjW8h0RrhHeAAcCfJBEP+UnKOTYB3xGRbwHHqGpbBnlw5H+BxH27nJ5KMJ2J7Lcufp/23TOqutFpBNfC/ucgyanAElV9R1XbgT+lfT9XVbscd5SfG+0t4Eif740CYArCyIa9KX93pXzuItHXCRLP1PiUGEa9qmYMauZIA/CiMwL+JXCxM8r9HyA5qr+PRFvz84BlqrrVZT9tKevnSgc936fU/e1R1U4AVe0g8aN5ryOTl2trtnP9PqSqyd5ZPwAWO1bS+cljqOr/krC+2oCHReTMLOSeB/yYFPeSB149eVKfiU72PwdBSd1ePNdKnGsgxWeEhykII2wWst/dRIp7J5Ungc84359Aonna2mwOIiKfItGJ9h72/xi/7Vgr3ZkxqroHWECiJ76bewkSbp8PBDy0l+zrgbEiUiUiR+PRUtmRb4CqPgxMJeG2C8oA9geSP5+yz2OBV1X1ZyQ6lJ4EvAf0D7DP3wDfcwLBXjzFfv//Z7KQFxKdkz8qIgNFpBcJt2Mm3GQ/gTLtPhtlTEEYYXMN0OgES1eT8I+n80ugynEHzQY+77itMjHViQu8DFwBnKmqW1R1OwmrYSUJZfBs2nZ3k7ByFuLOfBLZQkHwkv0p4DVgNfAzEvERN/oDD4nIC8DfgP8IeFyA/wvcJCLN9BypXwqsdFxSo0nMQ70VeMoJ2nsFqXHcQz/LcNyvk5hYagVZzrzozD3yQ+AZEtdoPQk3mx8vAJ0isjwlSH0GiftkFBHr5mqUPSLyDRKj9v/yWedvJALb24snWWUgIger6k7HgniARHv9BzJtl2F85e8AAAB3SURBVLL9QcASEjMhdhRKTuNATEEYZY2IPAAcR8LaeNtnvQ8BbU7g1ggRJ5X3bBKuwIXA1zWLHx4nbbdeVZ8ojISGF6YgDMMwDFcsBmEYhmG4YgrCMAzDcMUUhGEYhuGKKQjDMAzDFVMQhmEYhiumIAzDMAxX/j9HDBZBcNEBDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114894cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "fitted_cab_model0 = LinearRegression().fit(X_train, y_train)\n",
    "plot_cabs(fitted_cab_model0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.240661535615741"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_cab_model0.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there's still a lot of variation in cab pickups that's not being caught by a linear fit. And the linear fit is predicting massively more pickups at 11:59pm than at 12:00am. However, we can add columns to our design matrix for $TimeMin^2$ and $TimeMin^3$ and so on, allowing a wigglier polynomial that will better fit the data.\n",
    "\n",
    "We'll be using sklearn's `PolynomialFeatures` to take some of the tedium out of building the new design matrix. In fact, if all we want is a formula like $y \\approx \\beta_0 + \\beta_1 x + \\beta_2 x^2 + ...$ it will directly return the new design matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.  ,  0.25,  0.5 ,  0.75,  1.  ]),\n",
       " array([  9.  ,   9.25,   9.5 ,   9.75,  10.  ]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tra = PolynomialFeatures(3, include_bias=True)\n",
    "xx1 = np.linspace(0,1, 5)\n",
    "xx2 = np.linspace(9,10, 5)\n",
    "xx1, xx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.  ,   9.  ],\n",
       "       [  0.25,   9.25],\n",
       "       [  0.5 ,   9.5 ],\n",
       "       [  0.75,   9.75],\n",
       "       [  1.  ,  10.  ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx3 = np.concatenate([xx1.reshape(-1,1),xx2.reshape(-1,1)], axis = 1)\n",
    "xx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   9.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   8.10000000e+01],\n",
       "       [  2.50000000e-01,   9.25000000e+00,   6.25000000e-02,\n",
       "          2.31250000e+00,   8.55625000e+01],\n",
       "       [  5.00000000e-01,   9.50000000e+00,   2.50000000e-01,\n",
       "          4.75000000e+00,   9.02500000e+01],\n",
       "       [  7.50000000e-01,   9.75000000e+00,   5.62500000e-01,\n",
       "          7.31250000e+00,   9.50625000e+01],\n",
       "       [  1.00000000e+00,   1.00000000e+01,   1.00000000e+00,\n",
       "          1.00000000e+01,   1.00000000e+02]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tra = PolynomialFeatures(2, include_bias=False)\n",
    "tra.fit_transform(xx3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.73333333e+00,   4.53377778e+01,   3.05274370e+02],\n",
       "       [  2.18333333e+00,   4.76694444e+00,   1.04078287e+01],\n",
       "       [  1.41666667e+00,   2.00694444e+00,   2.84317130e+00],\n",
       "       ..., \n",
       "       [  1.96666667e+01,   3.86777778e+02,   7.60662963e+03],\n",
       "       [  1.17333333e+01,   1.37671111e+02,   1.61534104e+03],\n",
       "       [  1.42000000e+01,   2.01640000e+02,   2.86328800e+03]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_3 = PolynomialFeatures(3, include_bias=False)\n",
    "new_features = transformer_3.fit_transform(X_train)\n",
    "new_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few notes on `PolynomialFeatures`:\n",
    "\n",
    "- The interface is a bit strange. `PolynomialFeatures` is a 'transformer' in sklearn. We'll be using several transformers that learn a transformation on the training data and then apply that transformation on future data. On these (more typical) transformers it makes sense to have a `.fit()` and a separate `.transform()`. With PolynomialFeatures, the `.fit()` is pretty trivial, and we often fit and transform in one command, as seen above.\n",
    "- You rarely want to `include_bias` (a column of all 1s), since sklearn will add it automatically and statsmodels can just `add_constant` right before you fit to the design matrix\n",
    "- If you want polynomial features for a several different variables, you should call `.fit_transform()` separately on each column and append all the results to the design matrix (unless you also want interaction terms between the newly-created features). See `np.concatenate` for joining arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_cab_model3 = LinearRegression().fit(new_features, y_train)\n",
    "plot_cabs(fitted_cab_model3, transformer_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "\n",
    "**Questions**:\n",
    "1. Calculate the polynomial model's $R^2$ performance on the test set. \n",
    "2. Does the polynomial model improve on the purely linear model?\n",
    "3. Make a residual plot for the polynomial model. What does this plot tell us about the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "1. See code below\n",
    "2. Yes, the test set $R^2$ is higher, and the visual fit to both data sets is much better. It even looks like the predicted number of pickups at 11:59 pm and 12:00 am are nearly equal.\n",
    "3. See the code below. The residuals are much more evenly spread than with the linear model [not shown, but trust us], but they still don't look like an even spread of gaussian noise. This makes it unlikely that the statsmodel assumptions are valid, and we might want to be careful about trusting confidence intervals, etc, and we may want to search for other models entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# test r-squared\n",
    "print(\"Test R-squared:\", fitted_cab_model3.score(transformer_3.fit_transform(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "design_mat = transformer_3.fit_transform(X_train)\n",
    "\n",
    "prediction = fitted_cab_model3.predict(design_mat)\n",
    "residual = y_train - prediction\n",
    "plt.scatter(X_train, residual, label=\"Residual\")\n",
    "plt.axhline(0, color='k')\n",
    "\n",
    "plt.title(\"Residuals for the Cubic Model\")\n",
    "plt.ylabel(\"Residual Number of Taxi Pickups\")\n",
    "plt.xlabel(\"Time of Day (Hours Past Midnight)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "design_mat = X_train\n",
    "\n",
    "prediction = fitted_cab_model0.predict(design_mat)\n",
    "residual = y_train - prediction\n",
    "plt.scatter(X_train, residual, label=\"Residual\")\n",
    "plt.axhline(0, color='k')\n",
    "\n",
    "plt.title(\"Residuals for the Linear Model\")\n",
    "plt.ylabel(\"Residual Number of Taxi Pickups\")\n",
    "plt.xlabel(\"Time of Day (Hours Past Midnight)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other features\n",
    "Polynomial features are not the only constucted features that help fit the data. Because these data have a 24 hour cycle, we may want to build features that follow such a cycle. For example, $sin(24\\frac{x}{2\\pi})$, $sin(12\\frac{x}{2\\pi})$, $sin(8\\frac{x}{2\\pi})$. Other feature transformations are appropriate to other types of data. For instance certain feature transformations have been developed for geographical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px\">\n",
    "## Part 2: Multiple regression and exploring the Football data\n",
    "Let's move on to a truly interesting dataset. The data imported below were scraped by [Shubham Maurya](https://www.kaggle.com/mauryashubham/linear-regression-to-predict-market-value/data) and record various facts about players in the English Premier League. Our goal will be to fit models that predict the players' market value (what the player could earn when hired by a new team), as estimated by transfermrkt.com.\n",
    "\n",
    "`name`: Name of the player  \n",
    "`club`: Club of the player  \n",
    "`age` : Age of the player  \n",
    "`position` : The usual position on the pitch  \n",
    "`position_cat` :  1 for attackers, 2 for midfielders, 3 for defenders, 4 for goalkeepers  \n",
    "`market_value` : As on transfermrkt.com on July 20th, 2017  \n",
    "`page_views` : Average daily Wikipedia page views from September 1, 2016 to May 1, 2017  \n",
    "`fpl_value` : Value in Fantasy Premier League as on July 20th, 2017  \n",
    "`fpl_sel` : % of FPL players who have selected that player in their team  \n",
    "`fpl_points` : FPL points accumulated over the previous season  \n",
    "`region`: 1 for England, 2 for EU, 3 for Americas, 4 for Rest of World  \n",
    "`nationality`: Player's nationality  \n",
    "`new_foreign`: Whether a new signing from a different league, for 2017/18 (till 20th July)  \n",
    "`age_cat`: a categorical version of the Age feature  \n",
    "`club_id`: a numerical version of the Club feature  \n",
    "`big_club`: Whether one of the Top 6 clubs  \n",
    "`new_signing`: Whether a new signing for 2017/18 (till 20th July)  \n",
    "\n",
    "As always, we first import, verify, split, and explore the data.\n",
    "\n",
    "## Part 2.1: Import and verification and grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name             object\n",
      "club             object\n",
      "age               int64\n",
      "position         object\n",
      "position_cat      int64\n",
      "market_value    float64\n",
      "page_views        int64\n",
      "fpl_value       float64\n",
      "fpl_sel          object\n",
      "fpl_points        int64\n",
      "region          float64\n",
      "nationality      object\n",
      "new_foreign       int64\n",
      "age_cat           int64\n",
      "club_id           int64\n",
      "big_club          int64\n",
      "new_signing       int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>club</th>\n",
       "      <th>age</th>\n",
       "      <th>position</th>\n",
       "      <th>position_cat</th>\n",
       "      <th>market_value</th>\n",
       "      <th>page_views</th>\n",
       "      <th>fpl_value</th>\n",
       "      <th>fpl_sel</th>\n",
       "      <th>fpl_points</th>\n",
       "      <th>region</th>\n",
       "      <th>nationality</th>\n",
       "      <th>new_foreign</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>club_id</th>\n",
       "      <th>big_club</th>\n",
       "      <th>new_signing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alexis Sanchez</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>28</td>\n",
       "      <td>LW</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4329</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.10%</td>\n",
       "      <td>264</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Chile</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mesut Ozil</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>28</td>\n",
       "      <td>AM</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4395</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5.60%</td>\n",
       "      <td>167</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Petr Cech</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>35</td>\n",
       "      <td>GK</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1529</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.90%</td>\n",
       "      <td>134</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Theo Walcott</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>28</td>\n",
       "      <td>RW</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2393</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.50%</td>\n",
       "      <td>122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>England</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Laurent Koscielny</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>31</td>\n",
       "      <td>CB</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>912</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.70%</td>\n",
       "      <td>121</td>\n",
       "      <td>2.0</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name     club  age position  position_cat  market_value  \\\n",
       "0     Alexis Sanchez  Arsenal   28       LW             1          65.0   \n",
       "1         Mesut Ozil  Arsenal   28       AM             1          50.0   \n",
       "2          Petr Cech  Arsenal   35       GK             4           7.0   \n",
       "3       Theo Walcott  Arsenal   28       RW             1          20.0   \n",
       "4  Laurent Koscielny  Arsenal   31       CB             3          22.0   \n",
       "\n",
       "   page_views  fpl_value fpl_sel  fpl_points  region     nationality  \\\n",
       "0        4329       12.0  17.10%         264     3.0           Chile   \n",
       "1        4395        9.5   5.60%         167     2.0         Germany   \n",
       "2        1529        5.5   5.90%         134     2.0  Czech Republic   \n",
       "3        2393        7.5   1.50%         122     1.0         England   \n",
       "4         912        6.0   0.70%         121     2.0          France   \n",
       "\n",
       "   new_foreign  age_cat  club_id  big_club  new_signing  \n",
       "0            0        4        1         1            0  \n",
       "1            0        4        1         1            0  \n",
       "2            0        6        1         1            0  \n",
       "3            0        4        1         1            0  \n",
       "4            0        4        1         1            0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "league_df = pd.read_csv(\"data/league_data.txt\")\n",
    "print(league_df.dtypes)\n",
    "league_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(461, 17)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "league_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>position_cat</th>\n",
       "      <th>market_value</th>\n",
       "      <th>page_views</th>\n",
       "      <th>fpl_value</th>\n",
       "      <th>fpl_points</th>\n",
       "      <th>region</th>\n",
       "      <th>new_foreign</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>club_id</th>\n",
       "      <th>big_club</th>\n",
       "      <th>new_signing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>461.000000</td>\n",
       "      <td>461.000000</td>\n",
       "      <td>461.000000</td>\n",
       "      <td>461.000000</td>\n",
       "      <td>461.000000</td>\n",
       "      <td>461.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>461.000000</td>\n",
       "      <td>461.000000</td>\n",
       "      <td>461.000000</td>\n",
       "      <td>461.000000</td>\n",
       "      <td>461.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26.804772</td>\n",
       "      <td>2.180043</td>\n",
       "      <td>11.012039</td>\n",
       "      <td>763.776573</td>\n",
       "      <td>5.447939</td>\n",
       "      <td>57.314534</td>\n",
       "      <td>1.993478</td>\n",
       "      <td>0.034707</td>\n",
       "      <td>3.206074</td>\n",
       "      <td>10.334056</td>\n",
       "      <td>0.303688</td>\n",
       "      <td>0.145336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.961892</td>\n",
       "      <td>1.000061</td>\n",
       "      <td>12.257403</td>\n",
       "      <td>931.805757</td>\n",
       "      <td>1.346695</td>\n",
       "      <td>53.113811</td>\n",
       "      <td>0.957689</td>\n",
       "      <td>0.183236</td>\n",
       "      <td>1.279795</td>\n",
       "      <td>5.726475</td>\n",
       "      <td>0.460349</td>\n",
       "      <td>0.352822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>896.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>7664.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  position_cat  market_value   page_views   fpl_value  \\\n",
       "count  461.000000    461.000000    461.000000   461.000000  461.000000   \n",
       "mean    26.804772      2.180043     11.012039   763.776573    5.447939   \n",
       "std      3.961892      1.000061     12.257403   931.805757    1.346695   \n",
       "min     17.000000      1.000000      0.050000     3.000000    4.000000   \n",
       "25%     24.000000      1.000000      3.000000   220.000000    4.500000   \n",
       "50%     27.000000      2.000000      7.000000   460.000000    5.000000   \n",
       "75%     30.000000      3.000000     15.000000   896.000000    5.500000   \n",
       "max     38.000000      4.000000     75.000000  7664.000000   12.500000   \n",
       "\n",
       "       fpl_points      region  new_foreign     age_cat     club_id  \\\n",
       "count  461.000000  460.000000   461.000000  461.000000  461.000000   \n",
       "mean    57.314534    1.993478     0.034707    3.206074   10.334056   \n",
       "std     53.113811    0.957689     0.183236    1.279795    5.726475   \n",
       "min      0.000000    1.000000     0.000000    1.000000    1.000000   \n",
       "25%      5.000000    1.000000     0.000000    2.000000    6.000000   \n",
       "50%     51.000000    2.000000     0.000000    3.000000   10.000000   \n",
       "75%     94.000000    2.000000     0.000000    4.000000   15.000000   \n",
       "max    264.000000    4.000000     1.000000    6.000000   20.000000   \n",
       "\n",
       "         big_club  new_signing  \n",
       "count  461.000000   461.000000  \n",
       "mean     0.303688     0.145336  \n",
       "std      0.460349     0.352822  \n",
       "min      0.000000     0.000000  \n",
       "25%      0.000000     0.000000  \n",
       "50%      0.000000     0.000000  \n",
       "75%      1.000000     0.000000  \n",
       "max      1.000000     1.000000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "league_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Stratified) train/test split\n",
    "We want to make sure that the training and test data have appropriate representation of each region; it would be bad for the training data to entirely miss a region. This is especially important because some regions are rather rare.\n",
    "\n",
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "**Questions**:\n",
    "1. Use the `train_test_split` function to and its 'stratify' argument to split the data, keeping equal representation of each region (This will not work out of the box on this data. Deal with the resulting issue).\n",
    "2. Deal with the issue you encountered above.\n",
    "3. How did you deal with the error generated by `train_test_split`? How did you justify your action? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*:\n",
    "1. See below. We pass the `stratify` argument the data that we want to keep even across train and test sets.\n",
    "2. See below.\n",
    "2. Since only one data point has a missing value, we just drop it. +/- one point doesn't seem like it would impact the analysis too much. Of course, someone who knew the premier league might be able to tell which region this player should be in and simply correct the missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uh oh, 1 lines missing data! Dropping them\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "try:\n",
    "    # Doesn't work: a value is missing\n",
    "    train_data, test_data = train_test_split(league_df, test_size = 0.2, \n",
    "                                             stratify=league_df['region'])\n",
    "except:\n",
    "    # Count the missing lines and drop them\n",
    "    missing_rows = np.isnan(league_df['region'])\n",
    "    print(\"Uh oh, {} lines missing data! Dropping them\".format(np.sum(missing_rows)))\n",
    "    league_df = league_df.dropna(subset=['region'])\n",
    "    train_data, test_data = train_test_split(league_df, test_size = 0.2, \n",
    "                                             stratify=league_df['region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((368, 17), (92, 17))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we won't be peeking at the test set, let's explore and look for patterns! We'll introduce a number of useful pandas and numpy functions along the way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby\n",
    "Pandas' `.groupby()` function is a wonderful tool for data analysis. It allows us to analyze each of several subgroups.\n",
    "\n",
    "Many times, `.groupby()` is combined with `.agg()` to get a summary statistic for each subgroup. For instance: What is the average market value, median page views, and maximum fpl for each player position?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market_value</th>\n",
       "      <th>page_views</th>\n",
       "      <th>fpl_points</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AM</th>\n",
       "      <td>25.711538</td>\n",
       "      <td>1413.0</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB</th>\n",
       "      <td>9.476923</td>\n",
       "      <td>338.0</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CF</th>\n",
       "      <td>13.852041</td>\n",
       "      <td>781.0</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CM</th>\n",
       "      <td>11.361111</td>\n",
       "      <td>420.5</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DM</th>\n",
       "      <td>13.339286</td>\n",
       "      <td>477.0</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GK</th>\n",
       "      <td>6.237097</td>\n",
       "      <td>402.0</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LB</th>\n",
       "      <td>8.490741</td>\n",
       "      <td>345.0</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LM</th>\n",
       "      <td>4.375000</td>\n",
       "      <td>325.5</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LW</th>\n",
       "      <td>14.243548</td>\n",
       "      <td>474.0</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RB</th>\n",
       "      <td>7.824074</td>\n",
       "      <td>215.0</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>10.600000</td>\n",
       "      <td>566.0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RW</th>\n",
       "      <td>10.972222</td>\n",
       "      <td>454.0</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SS</th>\n",
       "      <td>7.300000</td>\n",
       "      <td>473.0</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          market_value  page_views  fpl_points\n",
       "position                                      \n",
       "AM           25.711538      1413.0         218\n",
       "CB            9.476923       338.0         178\n",
       "CF           13.852041       781.0         224\n",
       "CM           11.361111       420.5         225\n",
       "DM           13.339286       477.0         131\n",
       "GK            6.237097       402.0         149\n",
       "LB            8.490741       345.0         177\n",
       "LM            4.375000       325.5          99\n",
       "LW           14.243548       474.0         264\n",
       "RB            7.824074       215.0         170\n",
       "RM           10.600000       566.0         105\n",
       "RW           10.972222       454.0         162\n",
       "SS            7.300000       473.0         178"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby('position').agg({\n",
    "    'market_value': np.mean,\n",
    "    'page_views': np.median,\n",
    "    'fpl_points': np.max\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CF', 'CM', 'CB', 'GK', 'RW', 'DM', 'RB', 'LB', 'LW', 'AM', 'LM',\n",
       "       'SS', 'RM'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.position.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>market_value</th>\n",
       "      <th>page_views</th>\n",
       "      <th>fpl_points</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big_club</th>\n",
       "      <th>position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">0</th>\n",
       "      <th>AM</th>\n",
       "      <td>13.208333</td>\n",
       "      <td>563.166667</td>\n",
       "      <td>68.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB</th>\n",
       "      <td>4.771739</td>\n",
       "      <td>298.652174</td>\n",
       "      <td>41.152174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CF</th>\n",
       "      <td>8.878571</td>\n",
       "      <td>886.828571</td>\n",
       "      <td>55.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CM</th>\n",
       "      <td>5.687500</td>\n",
       "      <td>355.775000</td>\n",
       "      <td>38.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DM</th>\n",
       "      <td>7.777778</td>\n",
       "      <td>465.111111</td>\n",
       "      <td>42.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GK</th>\n",
       "      <td>4.137500</td>\n",
       "      <td>379.100000</td>\n",
       "      <td>44.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LB</th>\n",
       "      <td>5.065789</td>\n",
       "      <td>247.578947</td>\n",
       "      <td>51.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LM</th>\n",
       "      <td>4.375000</td>\n",
       "      <td>370.500000</td>\n",
       "      <td>52.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LW</th>\n",
       "      <td>6.309524</td>\n",
       "      <td>441.619048</td>\n",
       "      <td>45.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RB</th>\n",
       "      <td>4.750000</td>\n",
       "      <td>260.190476</td>\n",
       "      <td>51.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>4.333333</td>\n",
       "      <td>280.333333</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RW</th>\n",
       "      <td>7.967391</td>\n",
       "      <td>543.173913</td>\n",
       "      <td>48.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SS</th>\n",
       "      <td>7.300000</td>\n",
       "      <td>1969.000000</td>\n",
       "      <td>55.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">1</th>\n",
       "      <th>AM</th>\n",
       "      <td>36.428571</td>\n",
       "      <td>2473.857143</td>\n",
       "      <td>142.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB</th>\n",
       "      <td>20.868421</td>\n",
       "      <td>1016.789474</td>\n",
       "      <td>72.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CF</th>\n",
       "      <td>26.285714</td>\n",
       "      <td>2390.714286</td>\n",
       "      <td>84.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CM</th>\n",
       "      <td>27.571429</td>\n",
       "      <td>2158.142857</td>\n",
       "      <td>93.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DM</th>\n",
       "      <td>23.350000</td>\n",
       "      <td>1340.600000</td>\n",
       "      <td>63.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GK</th>\n",
       "      <td>10.054545</td>\n",
       "      <td>769.909091</td>\n",
       "      <td>52.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LB</th>\n",
       "      <td>16.625000</td>\n",
       "      <td>914.875000</td>\n",
       "      <td>70.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LW</th>\n",
       "      <td>30.905000</td>\n",
       "      <td>2150.100000</td>\n",
       "      <td>116.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RB</th>\n",
       "      <td>18.583333</td>\n",
       "      <td>994.166667</td>\n",
       "      <td>102.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>2028.000000</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RW</th>\n",
       "      <td>28.250000</td>\n",
       "      <td>1415.750000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   market_value   page_views  fpl_points\n",
       "big_club position                                       \n",
       "0        AM           13.208333   563.166667   68.666667\n",
       "         CB            4.771739   298.652174   41.152174\n",
       "         CF            8.878571   886.828571   55.428571\n",
       "         CM            5.687500   355.775000   38.325000\n",
       "         DM            7.777778   465.111111   42.722222\n",
       "         GK            4.137500   379.100000   44.900000\n",
       "         LB            5.065789   247.578947   51.526316\n",
       "         LM            4.375000   370.500000   52.833333\n",
       "         LW            6.309524   441.619048   45.523810\n",
       "         RB            4.750000   260.190476   51.904762\n",
       "         RM            4.333333   280.333333    1.666667\n",
       "         RW            7.967391   543.173913   48.695652\n",
       "         SS            7.300000  1969.000000   55.800000\n",
       "1        AM           36.428571  2473.857143  142.857143\n",
       "         CB           20.868421  1016.789474   72.526316\n",
       "         CF           26.285714  2390.714286   84.714286\n",
       "         CM           27.571429  2158.142857   93.714286\n",
       "         DM           23.350000  1340.600000   63.300000\n",
       "         GK           10.054545   769.909091   52.909091\n",
       "         LB           16.625000   914.875000   70.500000\n",
       "         LW           30.905000  2150.100000  116.900000\n",
       "         RB           18.583333   994.166667  102.833333\n",
       "         RM           20.000000  2028.000000   94.000000\n",
       "         RW           28.250000  1415.750000   78.000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby(['big_club', 'position']).agg({\n",
    "    'market_value': np.mean,\n",
    "    'page_views': np.mean,\n",
    "    'fpl_points': np.mean\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px\">\n",
    "## Part 2.2: Linear regression on the football data\n",
    "This section of the lab focuses on fitting a model to the football data and interpreting the model results. The model we'll use is\n",
    "\n",
    "$$\\text{market_value} \\approx \\beta_0 + \\beta_1\\text{fpl_points} + \\beta_2\\text{age} + \\beta_3\\text{age}^2 + \\beta_4log_2\\left(\\text{page_views}\\right) + \\beta_5\\text{new_signing} +\\beta_6\\text{big_club} + \\beta_7\\text{position_cat}$$\n",
    "\n",
    "We're including a 2nd degree polynomial in age because we expect pay to increase as a player gains experience, but then decrease as they continue aging. We're taking the log of page views because they have such a large, skewed range and the transformed variable will have fewer outliers that could bias the line. We choose the base of the log to be 2 just to make interpretation cleaner.\n",
    "\n",
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "**Questions**:\n",
    "1. Build a design matrix function and fit this model to the training data. How good is the overall model?\n",
    "2. Interpret the regression model. What is the meaning of the coefficient for:\n",
    "    - age and age$^2$\n",
    "    - $log_2($page_views$)$\n",
    "    - big_club\n",
    "2. What should a player do in order to improve their market value? How many page views should a player go get to increase their market value by 10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "# building design matrices happens after explore\n",
    "y_train = train_data['market_value']\n",
    "y_test = test_data['market_value']\n",
    "\n",
    "def build_model2_design(df):\n",
    "    design_mat = df[['fpl_points','age','new_signing','big_club','position_cat']].copy()\n",
    "    design_mat['log_views'] = np.log2(df['page_views'])\n",
    "    design_mat['age_squared'] = df['age']**2\n",
    "    \n",
    "    #reindex so variables are in a pretty order\n",
    "    design_mat = design_mat[['fpl_points','age','age_squared','log_views','new_signing','big_club','position_cat']]\n",
    "    \n",
    "    design_mat = sm.add_constant(design_mat)\n",
    "    \n",
    "    return design_mat\n",
    "\n",
    "train_design = build_model2_design(train_data)\n",
    "test_design = build_model2_design(test_data)\n",
    "\n",
    "fitted_model_1 = OLS(endog= y_train, exog= train_design, hasconst=True).fit()\n",
    "fitted_model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# test set r-squared\n",
    "r2_score(y_test, fitted_model_1.predict(test_design))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n",
    "1. The model is reasonably good. We're capturing about 67% of the variation in market values, and the test set confirms that we're not overfitting too badly.\n",
    "2. Look at the coefficients, depends upon your split..\n",
    "3. Linear regression on non-experimental data can't determine causation, so we can't prove that a given relationship runs in the direction we might think. For instance, doing whatever it takes to get more page views probably doesn't meaningfully increase market value; it's likely the causation runs in the other direction and great players get more views. Even so, we can use page views to help us tell who is a great player and thus likely to be paid well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agecoef = fitted_model_1.params.age\n",
    "age2coef = fitted_model_1.params.age_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = np.linspace(-100,100,1000)\n",
    "y_vals = agecoef*x_vals +age2coef*x_vals**2\n",
    "plt.plot(x_vals, y_vals)\n",
    "plt.title(\"Effect of Age\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Contribution to Predicted Market Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:3px'>\n",
    "### Part 2.3: Turning Categorical Variables into multiple binary variables\n",
    "Of course, we have an error in how we've included player position. Even though the variable is numeric (1,2,3,4) and the model runs without issue, the value we're getting back is garbage. The interpretation, such as it is, is that there is an equal effect of moving from position category 1 to 2, from 2 to 3, and from 3 to 4, and that this effect is about -.61.\n",
    "\n",
    "In reality, we don't expect moving from one position category to another to be equivalent, nor for a move from category 1 to category 3 to be twice as important as a move from category 1 to category 2. We need to introduce better features to model this variable.\n",
    "\n",
    "We'll use `pd.get_dummies` to do the work for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_design_recoded = pd.get_dummies(train_design, columns=['position_cat'], drop_first=True)\n",
    "test_design_recoded = pd.get_dummies(test_design, columns=['position_cat'], drop_first=True)\n",
    "\n",
    "train_design_recoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've removed the original `position_cat` column and created three new ones.\n",
    "\n",
    "#### Why only three new columns?\n",
    "Why does pandas give us the option to drop the first category? \n",
    "\n",
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "**Questions**:\n",
    "1. If we're fitting a model without a constant, should we have three dummy columns or four dummy columns?\n",
    "2. Fit a model and interpret the coefficient of `position_cat_2`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resu = OLS(y_train, train_design_recoded).fit()\n",
    "resu.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, resu.predict(test_design_recoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_design_recoded.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers**:\n",
    "1. If our model does not have a constant, we must include all four dummy variable columns. If we drop one, we're not modeling any effect of being in that category, and effectively assuming the dropped category's effect is 0.\n",
    "2. Being in position 2 (instead of position 1) has an impact between -1.54 and +2.38 on a player's market value. Since we're using an intercept, the dropped category becomes the baseline and the effect of any dummy variable is the effect of being in that category instead of the baseline category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: A nice trick for forward-backwards\n",
    "\n",
    "XOR (operator ^) is a logical operation that only returns true when input differ. We can use it to implement forward-or-backwards selection when we want to keep track of whet predictors are \"left\" from a given list of predictors.\n",
    "\n",
    "The set analog is \"symmetric difference\". From the python docs:\n",
    "\n",
    "`s.symmetric_difference(t)\ts ^ t\tnew set with elements in either s or t but not both`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set() ^ set([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([1]) ^ set([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([1, 2]) ^ set([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "\n",
    "Outline a step-forwards algorithm which uses this idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n",
    "Start with no predictors in a set, `selected_predictors`. Then the \"xor\" will give the set of all predictors. Go through them 1-by -1, seeing which has the highest score/ OR lowestaic/bic. Add this predictor to the `selected_predictors`.\n",
    "\n",
    "Now repeat. The xor will eliminate this predictor from the remaining predictors. In the next iteration we will pick the next predictor which when combined with the first one gibes the lowest aic/bic of all 2-predictor models.\n",
    "\n",
    "We repeat. We finally chose the best bic model from the 1 -predictor models, 2-predictor models, 3-predictor models and so on..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
